#+title: How to avoid cars and bikes when walking from A to B
#+author: Nicky van Foreest
#+date: 2022:03:24, 2022:07:08, <2022-08-01 ma>

#+LATEX_HEADER: \usepackage{standardStyle}

* Introduction

The Pieterpad is a long distance walking route in the Netherlands from the north to the south via paths, tracks, and small roads.
While walking this route with my wife we noticed that we prefer tracks over roads and stay away from the noise of motorways.
This made me wonder whether I could use data from OpenStreetMap and the shortest path algorithm to improve on the Pieterpad by increasing the fraction of tracks without making the overall length much longer.
This question lead to the project below.

In a mathematical sense the problem is simple: Make a graph of all roads, tracks, small roads, and so on of the Netherlands.
Next assign costs to each edge such that tracks have the lowest cost, small streets have slightly higher cost, and so on.
I also want to add extra costs to paths that lie near to motorways.
With these costs given, the best path from $A$ to $B$ is just the path with the least cost.
However, even though the Netherlands is (perceived to be) a small country, a graph of even part of our green country contains so many nodes and edges that 16 GB RAM does not suffice to run the shortest path algorithm with the =networkx= library.
Thus, finding the best path confronted me with some interesting problems.

Below I describe how I approached this problem.
In passing, we'll see how to use the nearest neighbor algorithms of =scikit.learn= to classify data and compute distances.
Next, we'll use =osmium= to unpack data from OpenStreetMap, =sqlite= to store and query data, and =networkx= to make graphs to clean up data and find the cheapest path.
Finally, with ~folium~ we plot the best path in a HTML page so that we can admire the best path in a browser.
We also write the path to a =gpx= file and a =kml= file so that we can import it in a mobile phone.

Note that I don't claim that this code can be used to  improve the Pieterpad; this path has been improved for many years by /humans/ (/not/ computers).
However, I find the code useful for making my own routes, for instance, the nicest route along all addresses at which my wife and I lived,  as a child with our parents,  and as parents with our own children.

* Getting the data

To download the map data I started with the Overpass API to OpenStreetMap, but that did not work really well; I needed too much data.
Therefore I downloaded the relevant ~pbf~ files from https://download.geofabrik.de/europe/netherlands.html.
For the Pieterpad I need the maps of Groningen, Drenthe, Overijssel, Gelderland and Limburg; I store the files in =~/tmp/=.
These files are very large when unzipped (many, many GBs), so it's better not to unzip them, but use =osmium= to parse them.



* Roads and edges

A ~pbf~ file stores location information with nodes.
Many such nodes correspond to /highways/, such as roads, tracks, paths, or trunks, while other nodes correspond to forest boundaries, lakes, and the like.
Clearly, for my project I only need the nodes related to highways.

A highway is a list of /node ids/, e.g.
~<nd ref="47803835"/>~, and /tags/, e.g., ~<tag k="highway" v="cycleway"/>~.
Sometimes there are tags with more information, e.g., ~<tag k="name" v="Schipborgerweg"/>~ and ~<tag k="surface" v="asphalt"/>~, but this is not always available.
Therefore we'll use just the list of node ids of a highway and the highway tag.
The nodes in a highway list are supposed to be connected.

We use =osmium= to read the data from a =.pbf= file.
To limit the memory usage, =osmium= offers a quite specific API.
(Consult the documentation for details.)

After having read the node data, we don't store it right away in a sqlite database.
First we form a graph $G$ of the data and remove all nodes that are not in the largest connected component of $G$;  such nodes cannot be reached from any publicly accessible road.

Once we have all relevant highway nodes, we need to read the gps coordinates, i.e., the latitude and longitude, of each node. We store this information also in the sql database.

* Computing edge lengths

The best path from $A$ to $B$ depends on the costs of the highways (in the OpenStreetMap sense).
As the highways form edges in a graph, we are henceforth concerned with edge costs.

Clearly, the cost of an edge should be a function of its length and its tag.
As the edge length does not depend on our preference for a certain type of highway, we compute that first with a simplified haversine formula. (Perhaps someday I type in the maths that underlies the approximation.)

* Setting edge costs

If we would follow the shortest path, we will walk many kilometers on primary and secondary roads.
To prevent this, we assign to each edge a cost which is the product of the edge length and a factor that depends on the highway tag.
A highway tagged as ~track~ gets a factor of 1 (Don't use a factor of zero as this  result in path with zero-cost cycles.)
Highways with other tags get a cost factor of at least 1, and often higher.

Using an extra factor seems to be OK, but it turns out that we can obtain paths with tracks that lie next to trunks.
(This is certainly not my idea of a nice walk.)
To prevent this, we multiply any edge in the neighborhood of a trunk with yet another factor that is also larger than 1.

This additional cost factor places us for the challenge to classify nodes as being near to a trunk or not.
For this, the =KDtree= of =scikit= is very useful.
After building the tree with the coordinates of the trunk nodes as data, we query the tree on the number of elements in the tree (i.e., the number of trunk nodes) that lie within a certain radius of a non trunk node.
If this number happens to be at least one, we classify the non trunk node as near to a trunk, and otherwise not.

Overall, tuning the costs required a bit more work than I anticipated.
My best attempt is in =common.py=.

* Compressing the graph

The text in this section is outdated for the moment (2202:07:08). One reason to compress the graph was to let =networkx= a bit faster. However, I think it's better to use another library altogether for larger networks, for instance =networkit=. As I did not try this yet, it might be that I have to compress after all. This is the next step in the project.

So far so good.
In fact, all of the above suffices to find optimal paths on small graphs.
However, for any path of somewhat serious size we need to compress the graph to a sub-graph with much less nodes and edges.

My first attempt was to simply remove nodes with very short edges.
Specifically, suppose I have three nodes $a, b, c$ connected with edges.
Writing $l(a,b)$ for the length in meters of the edge connecting nodes $a$ and $b$, then if $l(a,b) < 30$, I would add an edge between nodes $a$ and $c$, and remove node $b$ (with its edges).
This idea worked, but gives rough edges around road bends in the final path.
Moreover, the threshold of 30 is somewhat arbitrary, and worse, the idea is elegant nor efficient.

A much better idea is to /prune/ all nodes that have a degree of 2.
Consider again nodes $a, b, c$, and suppose $b$ has only nodes $a$ and $c$ as neighbors.
Then add an edge between $a$ and $c$ with edge cost $c(a,c) = c(a, b) + c(b, c)$, where $c(.,.)$ is the cost of an edge depending on its length and tag, and remove node $b$.

Pruning works, but not automatically.
Suppose we have a graph like this: $a-b-c-a$.
If we remove node $b$, then suddenly node $c$ has just node $a$ as its only neighbor.
Hence, in the process of short-circuiting nodes with degree 2, the degree of some nodes can become lower.
Since nodes with degree 1 are dead-ends, we can remove these right away, but nodes with degree 3 can become nodes with degree 2.
Hence, we should apply the same algorithm a few times.

Another slight complication arises when a node is connected to another node via different paths.
Consider, for instance, a graph with edges $a-b-c-d-e$ and a direct edge from $b$ to $d$.
If we prune node $c$, then we add an extra edge between $b$ and $d$.
Thus, we should keep the cheapest of both these edges while pruning.

The first 2 or 3 passes of this algorithm gives, by far, the largest reduction.
For safety we apply it 5 times to achieve a reduction in the number of nodes of about a factor 6.
We refer to the compressed graph as $C$.

Clearly, only after computing all the edge costs, we can compute the compressed graph $C$.

* The code

The code to run the above is in =port_info_to_database.py=.


* The best path

Now it's time to find the cheapest path from $A$ to $B$

We assume that $A$ and $B$ are specified as gps coordinates.
If you don't know the gps coordinates of points $A$ and $B$, go to [[https://www.openstreetmap.org/]], look up your point ~A~ on the map, right click with the mouse and select ~show address~.
In the pop up box you'll see the gps coordinates.

It might happen that $G$ does not contain $A$ and $B$.
To identify the node in $G$ that is closest to $A$, we again use a nearest neighbor tree.
For this we first select the nodes in $G$ within a small square around $A$; this square is simple to obtain from =sqlite=.
Then we build the tree with =scikit= from the nodes in the square and query for the node that is nearest to $A$.
(Finding the nearest node with =sqlite= is much less easy.)

The shortest path algorithm in =networkx= provides us with the cheapest path.
However, again to limit the number of nodes in the search graph we specify a thickened rectangle around the points $A$ and $B$ and use only the nodes in this rectangle in the graph.

The code is in =find_path.py= and it outputs the path to =html= with =folium=, to =gpx= and to =kml=.

Here is a handy kml viewer in the browser: https://www.doogal.co.uk/KmlViewer

* Things to TODO

- use =networkit= to find the shortest path.
- A-star for faster routing algorithm. This is also an example of recursion and flooding.
- k nearest neighbor with many  forest nodes, i.e, k big, in the neighborhood of a track node are a good sign (that you are in a forest). This may improve cost setting.
